{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv(r'../Datasets/churn_100k.csv')\n",
    "\n",
    "#* w11a.py:4: DtypeWarning: Columns (28) have mixed types. Specify dtype option on import or set low_memory=False.\n",
    "\n",
    "#* Classification, Scoring: 10.000 rows is low\n",
    "#* In scoring we may need even more (30-40 thousand)\n",
    "#* There is a good number of features, nice!\n",
    "\n",
    "#* 0: Settings\n",
    "TARGET = 'price'\n",
    "\n",
    "#* 1: Make the data usable\n",
    "\n",
    "def transformDollar( value ):\n",
    "    #: Delete, $ sign\n",
    "    value = str(value).replace('$', '')\n",
    "    #: Delete, , sign\n",
    "    value = value.replace(',', '')\n",
    "    #: Split by '.', get the first part\n",
    "    value = value.split('.')[0]\n",
    "    #: Transform into integer\n",
    "    value = int(value)\n",
    "    return value\n",
    "\n",
    "#: Replace the '$' sign in the prices\n",
    "df[TARGET] = df[TARGET].apply(transformDollar)\n",
    "\n",
    "#: Transform into a \"LOWER\" information\n",
    "# NOTE, Correlation only looks for \"non-empty\"\n",
    "\n",
    "#: Remove the columns which have mostly NULL\n",
    "del df['host_acceptance_rate']\n",
    "del df['square_feet']\n",
    "del df['monthly_discount']\n",
    "del df['weekly_discount']\n",
    "\n",
    "#* 2: Descriptive statistics\n",
    "\"\"\"\n",
    "from pandas_profiling import ProfileReport\n",
    "prof = ProfileReport(df)\n",
    "prof.to_file(output_file='w11_output.html')\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "for c in df:\n",
    "    null_ratio = len(df[df[c].isnull()]) / len(df)\n",
    "    if null_ratio > 0.0:\n",
    "        print(round(null_ratio, 2), c)\n",
    "\"\"\"\n",
    "\n",
    "fill_empty = {}\n",
    "for g in df.groupby(by = ['property_type']):\n",
    "    fill_empty[ g[0] ] = {\n",
    "        'bathrooms': g[1]['bathrooms'].mean(),\n",
    "        'beds': g[1]['beds'].mean(), \n",
    "        'bedrooms': g[1]['bedrooms'].mean()\n",
    "      }\n",
    "\n",
    "\n",
    "def fillby( row, what: str ):\n",
    "    \n",
    "    # NOTE, Sometimes, pandas may have a small problem regarding to \"nulls\"\n",
    "    if row[what] != None and not pd.isna(row[what]):\n",
    "        return row[what]\n",
    "    return fill_empty[ row['property_type'] ][ what ]\n",
    "\n",
    "df['bathrooms'] = df.apply(lambda row: fillby(row, 'bathrooms'), axis = 1)\n",
    "df['beds'] = df.apply(lambda row: fillby(row, 'beds'), axis = 1)\n",
    "df['bedrooms'] = df.apply(lambda row: fillby(row, 'bedrooms'), axis = 1)\n",
    "\n",
    "#* We tried, did not work\n",
    "df['name'] = df['name'].str.lower()\n",
    "df['wifi'] = df['name'].apply(lambda value: 'wifi' in value)\n",
    "\n",
    "\n",
    "def findWords( df, columnname: str ) -> dict:\n",
    "    output = {}\n",
    "\n",
    "    total = 0\n",
    "    for c in df[ columnname ].values:\n",
    "        c = str(c).split(' ')\n",
    "        for i in c:\n",
    "            if i not in output:\n",
    "                output[i] = 0\n",
    "            output[i] += 1\n",
    "            total += 1\n",
    "\n",
    "    for c in output:\n",
    "        output[c] = output[c] / total\n",
    "\n",
    "    newoutput = {}\n",
    "    for c in output:\n",
    "        if output[c] > 0.005:\n",
    "            newoutput[c] = output[c]\n",
    "\n",
    "    return newoutput\n",
    "\n",
    "\n",
    "df = df.sort_values(by = [TARGET])\n",
    "ucuz = df[ 0:  int(len(df) / 2)]\n",
    "bahali = df[ int(len(df) / 2): ]\n",
    "\n",
    "\"\"\"\n",
    "#* To find the differnet keywords used in \"bahali\" and \"ucuz\" houses\n",
    "df_high = df[ df['price'] > df['price'].mean() ] #* The items which are greater than 214 [ expensive ]\n",
    "df_low  = df[ df['price'] <= df['price'].mean() ] #* The items which are less than 214 [normal]\n",
    "\n",
    "high = findWords( df_high, 'name' )\n",
    "low = findWords( df_low, 'name' )\n",
    "\n",
    "\n",
    "print(high.keys())\n",
    "print(low.keys())\n",
    "\"\"\"\n",
    "\n",
    "bahali = ['family','pool','luxury']\n",
    "ucuz = ['private', 'studio']\n",
    "\n",
    "for c in bahali:\n",
    "    df[c] = df['name'].apply(lambda value: c in value)\n",
    "\n",
    "for c in ucuz:\n",
    "    df[c] = df['name'].apply(lambda value: c in value)\n",
    "\n",
    "df['lenname'] = df['name'].str.len()\n",
    "df['wcname'] = df['name'].apply(lambda value: len(value.split(' ')))\n",
    "del df['name']\n",
    "\n",
    "\n",
    "# TODO host_about house_rules summary\tspace\tdescription neighborhood_overview notes, transit, access, interaction,  -> these will be done, afternoon assignment\n",
    "\n",
    "#* Because there is only ONE value for the experiences_offered, we delete it\n",
    "del df['experiences_offered']\n",
    "\n",
    "\n",
    "df['house_rules'] = df['house_rules'].isnull()\n",
    "print(df['house_rules'].corr(df[TARGET]))\n",
    "\n",
    "#* We do not need this, because we already have host_since\n",
    "del df['host_id']\n",
    "\n",
    "#* from what time, the customer is with us\n",
    "df['host_since'] = pd.to_datetime( df['host_since'] ).dt.year\n",
    "\n",
    "#* NOTE, you can convert it to, FIRST, SECOND, THRID AND OTHERS?\n",
    "#! can also use df['host_location'] == df['host_location'].most()[0]\n",
    "df['host_location'] = df['host_location'] == 'Sydney, New South Wales, Australia'\n",
    "del df['host_location']\n",
    "\n",
    "\"\"\"\n",
    "IT DID NOT WORK OUT\n",
    "df = pd.get_dummies(df, columns = ['host_response_time'])\n",
    "for c in df:\n",
    "    if 'host_response_time' in c:\n",
    "        print(c, df[c].corr(df[TARGET]))\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "del df['host_response_time']\n",
    "\n",
    "\n",
    "def target_average(df, column: str, trgt):\n",
    "    d = df.groupby(by = [column]).agg({trgt:'mean'}).to_dict()[trgt]\n",
    "    df[column] = df[column].map(d)\n",
    "    print(column, df[column].corr(df[trgt]))\n",
    "    return df\n",
    "\n",
    "\n",
    "df = target_average(df, 'host_response_rate', TARGET )\n",
    "df = target_average(df, 'host_verifications', TARGET )\n",
    "\n",
    "#! IT IS NOT IMPORTANT WHEN THE OWNER HAS ANSWERED\n",
    "#! IT IS IMPORTANT THAT HE/SHE HAS ANSWERED\n",
    "\n",
    "del df['zipcode']\n",
    "\n",
    "\n",
    "df['room_type'] = df['room_type'] == 'Entire home/apt'\n",
    "\n",
    "#: We delete bed_type, because, most of the values are SAME %99\n",
    "del df['bed_type']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df['amenities'] = df['amenities'].apply(lambda value: str(value).replace(\"{\", \"\").replace(\"}\", \"\").split(','))\n",
    "df['len_amenities'] = df['amenities'].apply(lambda value: len(value))\n",
    "\n",
    "print(df['len_amenities'].corr(df[TARGET]))\n",
    "\n",
    "\n",
    "sub = df.select_dtypes(exclude = ['object'])\n",
    "sub = sub.dropna()\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=2)\n",
    "pca.fit(sub.drop(columns = [TARGET]))\n",
    "\n",
    "print(pca.explained_variance_ratio_)\n",
    "#! NOTE, DONT USE TARGET COLUMNS IN PCA\n",
    "transformed = pca.transform(sub.drop(columns = [TARGET]))  # 53x3993..\n",
    "\n",
    "\n",
    "transformed = pd.DataFrame(transformed)\n",
    "transformed.columns = ['c0', 'c1']\n",
    "transformed[TARGET] = sub[TARGET]\n",
    "transformed.to_csv(\"w11_pca.csv\")\n",
    "\n",
    "del transformed['c0']\n",
    "\n",
    "\n",
    "#! DISADVANTAGE: ONLY WORKS FOR LINEAR RELATIONS\n",
    "# PCA = bakis acisi, point of view\n",
    "\n",
    "\n",
    "less_important_features = []\n",
    "\n",
    "for c in sub:\n",
    "    corr = abs(sub[c].corr(sub[TARGET]))\n",
    "    if corr < 0.05:\n",
    "        less_important_features.append( c )\n",
    "        print(c, corr)\n",
    "\n",
    "\n",
    "pca = PCA(n_components=1)\n",
    "pca.fit( sub[ less_important_features ] )\n",
    "sub['PCA'] = pca.transform( sub[ less_important_features] )\n",
    "\n",
    "for c in less_important_features:\n",
    "    del sub[c]\n",
    "\n",
    "\n",
    "sub.to_csv(\"w11_sub.csv\")\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "X_embedded = TSNE(n_components=3, learning_rate='auto',\n",
    "                  init='random', perplexity=3).fit_transform(sub)\n",
    "sub[TARGET] = (sub[TARGET] - sub[TARGET].min()) / (sub[TARGET].max() - sub[TARGET].min())\n",
    "\n",
    "# plt.scatter(X_embedded[:,0], X_embedded[:,1], c = sub[TARGET])\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "# For each set of style and range settings, plot n random points in the box\n",
    "# defined by x in [23, 32], y in [0, 100], z in [zlow, zhigh].\n",
    "for i in range(len(X_embedded)):\n",
    "    \n",
    "    ax.scatter(X_embedded[i][0], X_embedded[i][1], X_embedded[i][2])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "medium cardinality:\n",
    "\thost_neighbourhood\n",
    "\tstreet\n",
    "\tneighbourhood\n",
    "\tcity\n",
    "\tsmart_location\n",
    "\t\n",
    "\n",
    "top 4 & others\n",
    "\tneighbourhood_cleansed\n",
    "\tproperty_type\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simplify_categories(data, column, top_n=3):\n",
    "    top_categories = data[column].value_counts().nlargest(top_n).index\n",
    "    data[f'{column}_simplified'] = data[column].apply(\n",
    "        lambda x: x if x in top_categories else 'Others'\n",
    "    )\n",
    "most_frequent_location = df['host_location'].value_counts().idxmax()\n",
    "df['host_location_is_most_frequent'] = df['host_location'] == most_frequent_location\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
